Generating 3D Models from Downward-Facing Aerial/Reef Videos
Modified from Young et al. 2017 by Michael Studivan (mstudiva@fau.edu)
Last Updated: Ian Combs 12/10/19
Note: The protocol is slightly different for aerial or reef videos, but the overall workflow is the same. Start with the appropriate subsection below depending on the application.
Note: The quality of the model will greatly depend on the target area. Reefscapes with high densities of moving organisms, such as fish and soft corals, will prevent good alignment of points across photos. Likewise, aerial videos over large areas may result in variability due to trees or birds moving. In highly variable areas, it is suggested to reduce the size of the video area and make sure your target of interest (corals, buildings, etc.) are not too close to moving objects.

------------------------------
Aerial Videography

Note: We are using a DJI Inspire 1 with Zenmuse X3 camera as it produces very little lens distortion, shoots in 4K, and has excellent video stabilization.

1.	Locate the boundaries of the area to be mapped and determine the optimum number of tracks needed to cover the entire area with a single quadcopter flight.
2.	Deploy the quadcopter and ascend to a preset altitude. We find that 400ft allows for sufficient ground coverage and sufficient image quality for mapping.
3.	Orient the camera to 90° facing downwards and maintain the same quadcopter heading.
4.	Fly a grid pattern over the entire target area (Figure 1), maintaining the same altitude and heading (do not adjust the quadcopter yaw; this requires you to move side-to-side and backwards).
5.	Take continuous video along the flight, ensuring complete coverage with overlapping features.
    a.	If mapping a large area over multiple flights, try to maintain lighting consistency by either flying immediately after the first flight, or flying at the same time of day.

------------------------------
Reef Videography

1.	The type of underwater camera should not matter for model generation, however, ensure it shoots in sufficient quality (1080p). If using a GoPro, make sure the field of view is set to narrow, sharpness to medium, frame rate of at least 30 fps, and white balance of 6500K. External lights should not be needed
    a.	Note: We use a Canon G16 with the underwater mode, shooting at 60 fps. There is very little lens distortion, and it has an excellent sensor for video stabilization.
2.	Once you have identified a target area, lay down some kind of scaling reference. You can build a 2 x 2 m PVC quadrat as in Young et al. (2017), or have several individual pieces of the same length PVC arranged in a square shape. It helps to add some kind of tape marker to each piece, such as a 10 cm scaling band.
    b. Note: We use two scaled PVC "L" frames with a 10 cm marking on either end
3.	Swim over the target area and scaling references in a lawnmower pattern while recording a single video (Figure 2). The diver should maintain a constant altitude (0.5–1 m off bottom) and relatively slow speed. Keep the camera oriented straight down and do not change the orientation in between adjacent passes.
    a.	The number of passes depends on the overall size of the target area. For a 2 x 2 m area, six adjacent passes should be sufficient to maintain >50% overlap between passes.
4.	At the end of the first set of passes, rotate the camera 90 and complete another set of passes, continuing to record
5.	A full set of two passes should take anywhere between 1–3 minutes.


------------------------------
Video Processing

Below is the protocol for extracting one round of stills from one model, included in this repository is a python script (ffmpeg.py) that will batch extract videos using Ffmpeg. 

Note: Dealing with high quality video, hundreds of stills, and high resolution models can require immense storage and computing requirements. I would suggest using a high speed, high capacity external drive for storage and local access. Most networked drives will likely be too slow for model generation and data curation.

1.	Install FFmpeg on your computer from http://www.ffmpeg.org/download.html. It is available for any OS and they provide several guides for installation.
    a.	Personally, I find it easiest to use on a Mac due to the Unix interface already set up in the Terminal app. The subsequent instructions are tailored for a Mac OS.
    b.	You may need additional software to run this on a Windows OS. Something like Cygwin (https://cygwin.com/install.html) should work.
2.	Navigate to the directory containing your video.
        cd /path/to/video/directory
3.	To pull still images from the video, use the following code:
        ffmpeg -i movie_filename.MP4 -vf fps=3 output_name_%d.png
    a.	-i denotes the input video filename
    b.	-vf deinterlaces the video to produce crisp still images
    c.	fps=3 specifies that 3 frames should be taken per second of video, which should be sufficient to produce images with enough overlap
    d.	Start the output filename as a text string of your choice, and %d inserts a consecutive number to each individual image file.
4.	Once the process finishes, you should have 100–500 still images depending on the length of the input video.

------------------------------
3D Model Generation

Note: While both software applications, Metashape and Rhino 3D, are not free, they offer educational licenses that are relatively affordable. Additionally, older versions of Netfabb are available for free on Windows and Mac OS (https://github.com/3DprintFIT/netfabb-basic-download/releases/tag/v7.4.0). Netfabb is less performance-intensive, but I have not figured out an easy way to scale the models and quantify area of user-specified polygons.

Note: Also, the two software applications, Metashape and Rhino 3D, require some serious computing power. It is recommended to meet their requirements, and to not attempt additional processing for other tasks while the models are being generated.

1.	Open Metashape and select Preferences. Under the GPU tab, make sure any available GPU devices are selected.
2.	The next steps are for High-Throughput, for single model generation skip to Step 7: Before you begin importing photos and generating models, we will create and save several batch processes. Select Workflow > Batch Process. Select Add, select Job type: Align Photos, Apply to: All Chunks. Under settings, the Accuracy Value defaults to High, double click and select Medium. Select OK. Select the box “Save project after each step” name and save your batch process “Batch Align” or a similarly appropriate name.
3.	In the same window, select Remove, then select Add, Job Type: Build Dense Cloud, Apply to: All Chunks. The Quality setting should default to Medium, if not, double click and select Medium. Select OK. Select the box “Save project after each step,” name and save your batch process “Batch Dense Cloud” or a similarly appropriate name.
4.	In the same window, select Remove, then select Add, Job Type: Build Mesh, Apply to: All Chunks. The Custom face count should be set to 3,000,000 for high accuracy. Select OK.
5.	In the same window, Select Add, Job type: Build Texture, Apply to: All Chunks. Select OK. Select the box “Save project after each step,” name and save your batch process “Batch Texture” or a similarly appropriate name.

Note: The reasoning behind the three separate batch processes is that there are important QA/QC procedures between the Alignment and Dense Cloud generations.

6.	Select the Add Chunk icon in the Workspace Window. Right click on the new Chunk and select Add > Add Photos. Navigate to your working directory and select all of the still images. Once imported, they will show up as a Chunk (set of photos). Rename the Chunk to distinguish this model from subsequent models. Repeat this process for all the remaining models you wish to make. Save the project.
7.	For single model generation: Select the Add Photos icon in the Workspace window. Navigate to your working directory and select all of the still images. Once imported, they will show up as a Chunk (set of photos). Save the project.
8.	Start the image alignment process by selecting Workflow, Align Photos. Set the Accuracy to Medium. This process may take some time, since it finds common points among the photos.
    a.	For High-Throughput process: Start the image alignment process by selecting Workflow, Batch Processes. Load the first batch process you made “Batch Align.” Click OK.
9.	Check the alignment by looking at the Photos window under View. Each photo will show up as a thumbnail; if it has aligned, you will see a green check mark. You can also check the aligned photo placement in the sparse point cloud in the Model window. Select the Show Cameras icon to see where the program thinks they were taken. The blue camera icons should approximately match the path taken in the original video. Use each of the three colored axes on the model sphere to move in 3 dimensional space, and scroll to zoom in and out.
    a.	If all the photos aligned correctly, proceed to the next step.
    b.	If some did not align properly, you can select the particular photos and Select Align Photos again.
10.	Select Resize Region. Ensure that the Region (the gray box) encompasses the entirety of your model (make sure to check the X, Y, and Z plane). The remaining steps only take into account what is located inside the Region.
    a.	For High-Throughput: Ensure this is done for each Chunk.
11.	Once enough photos are aligned, select Build Dense Cloud under Workflow. Set the Quality to Medium and start the process. This step takes the longest, and I would suggest selecting Background, which moves the process to the background and automatically saves the project upon completion.
    a.	For High-Throughput: Select Workflow, Batch Processes. Load the second batch process you made “Batch Dense Cloud.” Click OK.
12.	Once finished, you should have a decent representation of the model features built from many small points.
    a.	Check all angles of the point cloud, looking for aberrant features (“floaters”), or areas with moving features such as soft corals or trees.
    b.	Since these will not be well represented in the finished model, they should be removed. Position the model so that the problem features are isolated from the other parts of the model (nothing behind the features). Use the Rectangle Selection tool on the toolbar to highlight any offending points, and select the Delete Selection tool on the toolbar.
    c.	Don’t worry if this creates small gaps, as they will be filled in when the mesh is made. You do, however, have to remove all the problem features at this stage, otherwise you will have holes in your mesh.
13.	Start the Build Mesh process from the Workflow menu. Change the Face Count to 3,000,000 for high accuracy. This process is much shorter, but still can take 5–10 minutes.
    a.	For High-Throughput: Select Workflow, Batch Processes. Load the second batch process you made called “Batch Texture.” Click OK. (This batch process combines steps 13 and 14, which are relatively quick, use the QA/QC procedures below and rerun as normal if needed.)
    b.	Now you should have a smoothed version of the point cloud. Check for any lingering problem features.
    c.	If anything is found, switch back to the Dense Point Cloud using the button on the toolbar, remove them as described above, and regenerate the mesh.
14.	Start the Build Texture process from the Workflow menu, which may take another 5–10 minutes. Once completed, the photo texture will be mapped to the 3D model.
15.	Export the model by selecting File, Export, Export Model. Save it as a Wavefront OBJ (.obj) file. Make sure that Export Texture is selected in the following window. Saving as {chunklabel} will give your file names the same labels as your chunks.

------------------------------
3D Model Scaling and Analysis

Note: This protocol in based on Grace Young’s protocols on texture troubleshooting (https://www.graceunderthesea.com/thesis/photoscan-gt-rhino-not-importing-texture), orientation and scaling (https://www.graceunderthesea.com/thesis/how-to-rotate-3-points-flat-in-rhino), and quantitative analysis (https://www.graceunderthesea.com/thesis/rhino-3d-tutorials).

Note: If you are having slow performance working with models in Rhino, you can change the view from quad to single on the top toolbar. Working in quad may also cause texture rendering problems on large or complex models. But, you can of course switch back and forth between views as necessary for the analyses.

1.	Open the .obj file using Rhino 3D and save as a project file .3dm (with Save Textures checked).
2.	The texture created by Metashape should automatically appear on the mesh (model).
    a.	If it does not, first right click in each of the 4 windows and make sure Rendered view is selected.
    b.	No luck still? Select the mesh (will appear yellow when selected), then select the Object Properties pane on the right (hollow circle symbol on Mac). Remap the texture under Material, Edit, Textures, and select Color. The map file can be relocated by selecting the dropdown next to Map File.
3.	In the top right panel, there should be a list of layers. Rename the Default to something like Base or Mesh. Right click to add new layers, one each for Scale, Coral, Disease. As you are working with the respective objects, select the appropriate layer to assign the objects. You can then toggle the layer visibility using the light bulb icon.
4.	The first steps are to scale the model from a feature of known measure and to orient the model in 3D space. These objects should be placed in each area that is to be modeled, and can be any reasonable object that is highly differentiated from the surrounding environment (we use PVC segments).
5.	Model scaling: Our tracked colonies are all uniquely identified with cattle tags, however we have found that using scaled PVC "L" frames with 10 cm markings work best to scale the model.
    a.	You can also use the cattle tags, however there may be slight distortion of the cattle tags based on where they are placed on the colony.
    b.	Add points to the sides of the scale object based on your dimension of choice (we use 10 cm marking on our PVC frames) by typing Points into the command line. Make sure On Mesh is selected in the Object Snaps panel. Enter when done.
    d.	Run DimAligned in the command line. Make sure Point is selected in the Object Snaps panel and select each of the two scale points. Once entered, an arbitrary length should appear. Drag the scale bar with number outside the model boundaries and left click to release.
    e.	Select File, Settings, Dimensions, and set the Precision to the highest number of decimal points.
    f.	Select all (Cmd+A) and run Group in the command line.
    g.	Run Scale in the command line, select the mesh group (if not already selected), then select one of the scale points.
    h.	When prompted for the scaling factor in the top left panel, enter the known dimension divided by the arbitrary scaling length from step d (e.g. 100/2.1320067).
    i.	Change the units by selecting File, Settings, Units, and set the Model Units to meters. When prompted, select Yes to rescale the model.
    j.	Change the grid by selecting File, Settings, Grid, and set the Grid Line Count to 20 and the Minor Grid Lines Every 0.1m.
    k.	Reframe the model using View, Zoom, Zoom Extents All.
6.	Check the area of the whole model by selecting all, then typing Area into the command line. The full area will be displayed in m2.
7.	You can make the scale arrows and text smaller by selecting File, Settings, Dimensions, Sizes (Text height: 0.1) and Arrows (Dimension arrows Length: 0.1).
8.	(Optional) Note: This step has no affect on the measurements you take, but may be useful in orienting the model and making it easier to work with.
  To align the model on the X-Y plane:
    a.	Get the model in the full viewframe by selecting View, Zoom, Zoom Extents All.
    b.  Right click the mesh and set the view to Technical (easier to see points).
    c.	Make sure the Object Snap menu is always visible (defaults to bottom left panel on Mac). If it’s not already there, select Tools, Object Snap, Show Object Snaps Panel.
    d.	Type Points in the command prompt (top left panel), and select Persistent and On Mesh in the Object Snaps panel.
    e.	Select the polygon mesh by clicking once on the mesh.
    f.	The pointer should change to a crosshair. Add 3 points to PVC corners (outer boundaries of the quadrat or PVC markers). Hit Enter when done adding points.
    g.	Select all (Cmd+A) then type Group into the command line. Enter to group.
    h.	Type Move in the command line then Enter. Select the mesh (if not already selected) then Enter.
    i.	Select Point on the Object Snaps panel. It will be hard to find the center point (what you want to be at the origin) with the selected mesh, but you can move the mouse in the selected area when zoomed in.
    j.	Once you find the correct point, select it. Select the Move To location by finding the X-Y origin. Make sure Grid Snap is selected in the top toolbar and zooming helps. Select the origin and the model should automatically align the point.
    k.	In the Top view, enter the command Rotate, then select the grouped mesh and Enter. Select the center of rotation (point at origin), then select the angle or first reference point (another point you want on the x-axis). Enter, then it will ask for the second reference point. Make sure Ortho is selected on the top toolbar, then rotate the model so the second point rests on the x-axis.
    l.	Switch to Front or Right views and repeat step j twice to align to the x- and y-axes. The resulting points should be on the x and y-axes, with the model relatively aligned.
9.	Now it’s time to start creating objects for the living coral tissue and disease lesions. Start by switching to the appropriate layer.
10.	Create a polygon using the PolylineOnMesh icon in the top left panel. Select the base mesh, then begin drawing the polyline around the target object.
11.	Once finished, connect the ending and starting points.
12.	The object (called a curve) will be used to create a surface to measure area, but since it is on the mesh, cannot be used for calculations by itself.
13.	Right click on the Surface from 3 or 4 Corner Points icon to bring up the Surface Creation window.
14.	Select the Drape icon. Draw the window around an area encompassing your curve(s).
  Note: The secondary mesh generated by the drape may behave oddly around vertical features, especially if your coral colony is directly adjacent to larger features, in certain instances where the draped mesh is creating undesirable artifacts we have found it useful to invert the model and drape the mesh on the underside of the model.
15. Run Trim in the command line. Select the curve(s). Enter or select Done. Under "Select object to trim:" select an area on the Drape outside your curve. Enter or select Done. This should remove all the surface except for what is captured within your curves.
    a. If you have many small curves to trim from one drape over a large area, run Trim, then type SelSmall into the command line when it asks to select the cutting objects. Enter, then change the maximum length to a threshold that will select all your curves (I used 0.5). When you Enter, all the curves should be selected. Then Enter to end selection of cutting objects, and then select the drape as the object to trim.
16.	Once the surface is generated, select it and then type Area in the command line. The surface area should appear in the bottom right panel. Copy the value over to an Excel spreadsheet. You can also group all objects of the same type and get a cumulative area, but you lose the individual area values.
17.	Repeat steps 9-15 with other target objects, making sure to switch to the correct layer and toggling visibility to see overlapping layers.
